{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_iAN7cAthma"
      },
      "source": [
        "### Install Cellpose-SAM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hG3LSmJmLylT"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://www.github.com/mouseland/cellpose.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnKdFgZTqmE9"
      },
      "source": [
        "Check GPU and instantiate model - will download weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "5ydQ-fggSiUm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from cellpose import models, core, io, plot\n",
        "from pathlib import Path\n",
        "from tqdm import trange\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "io.logger_setup() # run this to get printing of progress\n",
        "\n",
        "#Check if colab notebook instance has GPU access\n",
        "if core.use_gpu()==False:\n",
        "  raise ImportError(\"No GPU access, change your runtime\")\n",
        "\n",
        "model = models.CellposeModel(gpu=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plEha5EaqmE9"
      },
      "source": [
        "Input directory with your images (if you have them, otherwise use sample images):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "cellView": "form",
        "id": "-lZP6alpUAfY"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import re\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "from tifffile import imread\n",
        "from cellpose import models, io, train\n",
        "\n",
        "image_dirs = [\n",
        "    Path(\"/scratch/msa6093/Daphnia392/XLayers-1000-2000\"),\n",
        "    Path(\"/scratch/msa6093/Daphnia392/ZLayer-200\")\n",
        "]\n",
        "mask_dir = Path(\"/scratch/msa6093/Daphnia392/CuratedTrainingData\")\n",
        "\n",
        "# Sanity check\n",
        "for d in image_dirs + [mask_dir]:\n",
        "    if not d.exists():\n",
        "        raise FileNotFoundError(f\"Directory not found: {d}\")\n",
        "\n",
        "mask_ext = \".nii.gz\"\n",
        "\n",
        "# regex to pull axis and layer from folder name, e.g. \"ZLayer-200\" → (\"Z\", \"200\")\n",
        "dir_re   = re.compile(r'^([XZ])Layers?-?(\\d+)$', re.IGNORECASE)\n",
        "# regex to pull slice index from filename stem, e.g. \"..._28\" → \"28\"\n",
        "slice_re = re.compile(r'_(\\d+)$')\n",
        "\n",
        "img_paths = []\n",
        "mask_paths = []\n",
        "\n",
        "for img_dir in image_dirs:\n",
        "    dir_match = dir_re.match(img_dir.name)\n",
        "    if dir_match:\n",
        "        axis  = dir_match.group(1).upper()\n",
        "        layer = int(dir_match.group(2))\n",
        "    else:\n",
        "        axis = layer = None\n",
        "\n",
        "    for img_f in sorted(img_dir.glob(\"*.tif\")):\n",
        "        if axis is not None:\n",
        "            sm = slice_re.search(img_f.stem)\n",
        "            if not sm:\n",
        "                pri\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJFJG-mkqmE-"
      },
      "source": [
        "## Train new model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0umDFliqmE-"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import re\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "from tifffile import imread\n",
        "from cellpose import models, train\n",
        "\n",
        "image_dirs = [\n",
        "    Path(\"/scratch/msa6093/Daphnia392/XLayers-1000-2000\"),\n",
        "    Path(\"/scratch/msa6093/Daphnia392/ZLayer-200\")\n",
        "]\n",
        "mask_dir = Path(\"/scratch/msa6093/Daphnia392/CuratedTrainingData\")\n",
        "mask_ext = \".nii.gz\"\n",
        "\n",
        "# regex: capture “X” or “Z” then “Layer” or “Layers”, then everything after the dash\n",
        "dir_re   = re.compile(r'^([XZ])Layers?-?(.+)$', re.IGNORECASE)\n",
        "slice_re = re.compile(r'_(\\d+)$')  # captures the trailing _<slice> in the filename\n",
        "\n",
        "img_paths, mask_paths = [], []\n",
        "for img_dir in image_dirs:\n",
        "    m = dir_re.match(img_dir.name)\n",
        "    if not m:\n",
        "        print(f\"skipping dir `{img_dir.name}` (didn't match axis+layer)\")\n",
        "        continue\n",
        "\n",
        "    axis, layer = m.group(1).upper(), m.group(2)  # layer is now e.g. \"200\" or \"1000-2000\"\n",
        "    for tif in sorted(img_dir.glob(\"*.tif\")):\n",
        "        sm = slice_re.search(tif.stem)\n",
        "        if not sm:\n",
        "            print(f\"skipping `{tif.name}` (no _<slice> to parse)\")\n",
        "            continue\n",
        "        slice_idx = sm.group(1)\n",
        "        mask_name = f\"predicted-{axis}{layer}-{slice_idx}{mask_ext}\"\n",
        "        mask_file = mask_dir / mask_name\n",
        "        if mask_file.exists():\n",
        "            img_paths.append(tif)\n",
        "            mask_paths.append(mask_file)\n",
        "        else:\n",
        "            print(f\"⏭  no mask for {tif.name} → expected `{mask_name}`\")\n",
        "\n",
        "if not img_paths:\n",
        "    raise RuntimeError(\"No image↔mask pairs found. Check your folder names & mask naming.\")\n",
        "\n",
        "print(f\"Found {len(img_paths)} pairs\")\n",
        "\n",
        "# load images with tifffile, masks with nibabel\n",
        "train_data   = [imread(str(p))                            for p in img_paths]\n",
        "train_labels = [nib.load(str(p)).get_fdata().astype(np.uint8) for p in mask_paths]\n",
        "\n",
        "# training\n",
        "model = models.CellposeModel(gpu=True)\n",
        "new_model_path, train_losses, test_losses = train.train_seg(\n",
        "    model.net,\n",
        "    train_data      = train_data,\n",
        "    train_labels    = train_labels,\n",
        "    batch_size      = 1,\n",
        "    n_epochs        = 100,\n",
        "    learning_rate   = 1e-5,\n",
        "    weight_decay    = 0.1,\n",
        "    nimg_per_epoch  = max(2, len(train_data)),\n",
        "    model_name      = \"CuratedTrainingData_May30_2Axes\",\n",
        "    min_train_masks = 1\n",
        ")\n",
        "\n",
        "print(f\"Training complete, model saved to: {new_model_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gj0EdXtcqmE-"
      },
      "source": [
        "## Evaluate on test data (optional)\n",
        "\n",
        "If you have test data, check performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Y2Gv4KnSqmE-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from tifffile import imread, imwrite\n",
        "import nibabel as nib\n",
        "from cellpose import models, metrics\n",
        "\n",
        "\n",
        "# path to the folder containing test images\n",
        "test_dir = Path(\"/scratch/msa6093/OverlappingPatches-Y\")\n",
        "\n",
        "# (optional) path to the folder containing ground‐truth masks\n",
        "gt_dir   = Path(\"/path/to/your/gt_masks\")\n",
        "\n",
        "# where to save the predicted masks\n",
        "out_dir  = test_dir / \"/scratch/msa6093/Full_Masks_Overlapping_Y\"\n",
        "\n",
        "# trained Cellpose model file\n",
        "trained_model = \"/scratch/msa6093/Daphnia392/models/CuratedTrainingData_May28_2Axes\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# make sure output directory exists\n",
        "out_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# gather all image files in test_dir\n",
        "img_exts = {\".tif\", \".tiff\", \".png\", \".jpg\", \".jpeg\"}\n",
        "nii_exts = (\".nii\", \".nii.gz\")\n",
        "\n",
        "# gather all image files in test_dir\n",
        "img_files = sorted([\n",
        "    f for f in test_dir.iterdir()\n",
        "    if f.suffix.lower() in img_exts\n",
        "       or f.name.lower().endswith(nii_exts)\n",
        "])\n",
        "\n",
        "# load images\n",
        "def load_image(path: Path):\n",
        "    if path.name.lower().endswith(nii_exts):\n",
        "        img = nib.load(str(path))\n",
        "        arr = img.get_fdata()\n",
        "        # if this is a 3D volume, you might want to decide how to handle it—\n",
        "        # here we assume 2D or single-slice\n",
        "        return np.asarray(arr, dtype=np.float32)\n",
        "    else:\n",
        "        return imread(str(path)).astype(np.float32)\n",
        "\n",
        "# load images\n",
        "test_data = [load_image(f) for f in img_files]\n",
        "\n",
        "# load ground‐truth if available\n",
        "if gt_dir.exists():\n",
        "    mask_files = sorted([\n",
        "        f for f in gt_dir.iterdir()\n",
        "        if f.suffix.lower() in img_exts\n",
        "           or f.name.lower().endswith(nii_exts)\n",
        "    ])\n",
        "    test_labels = [load_image(f) for f in mask_files]\n",
        "else:\n",
        "    test_labels = None\n",
        "\n",
        "# initialize your trained Cellpose model\n",
        "model = models.CellposeModel(gpu=True, \n",
        "                            pretrained_model=trained_model)\n",
        "\n",
        "# run inference\n",
        "masks, flows, styles = model.eval(test_data, batch_size=32)\n",
        "\n",
        "### # evaluate if ground‐truth was provided\n",
        "### if test_labels is not None:\n",
        "###     ap = metrics.average_precision(test_labels, masks)[0]\n",
        "###     mean_ap50 = ap[:,0].mean()\n",
        "###     print(f\">>> average precision at IoU=0.5 : {mean_ap50:.3f}\\n\")\n",
        "\n",
        "# save out each predicted mask\n",
        "for img_path, mask in zip(img_files, masks):\n",
        "    out_path = out_dir / f\"{img_path.stem}_mask.tif\"\n",
        "    # cast to uint16 (or uint8) as needed\n",
        "    imwrite(str(out_path), mask.astype(np.uint16))\n",
        "\n",
        "print(f\"Saved {len(masks)} predicted masks to:\\n  {out_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OddRFdtEqmE-"
      },
      "source": [
        "plot masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from tifffile import imread, imwrite\n",
        "import nibabel as nib\n",
        "from cellpose import models, metrics\n",
        "\n",
        "\n",
        "# path to the folder containing test images\n",
        "test_dir = Path(\"/scratch/msa6093/OverlappingPatches-Y/s3\")\n",
        "\n",
        "# (optional) path to the folder containing ground‐truth masks\n",
        "gt_dir   = Path(\"/path/to/your/gt_masks\")\n",
        "\n",
        "# where to save the predicted masks\n",
        "out_dir  = test_dir / \"/scratch/msa6093/Full_Masks_Overlapping_Y/s3\"\n",
        "\n",
        "# trained Cellpose model file\n",
        "trained_model = \"/scratch/msa6093/Daphnia392/models/CuratedTrainingData_May28_2Axes\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# make sure output directory exists\n",
        "out_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# gather all image files in test_dir\n",
        "img_exts = {\".tif\", \".tiff\", \".png\", \".jpg\", \".jpeg\"}\n",
        "nii_exts = (\".nii\", \".nii.gz\")\n",
        "\n",
        "# gather all image files in test_dir\n",
        "img_files = sorted([\n",
        "    f for f in test_dir.iterdir()\n",
        "    if f.suffix.lower() in img_exts\n",
        "       or f.name.lower().endswith(nii_exts)\n",
        "])\n",
        "\n",
        "# load images\n",
        "def load_image(path: Path):\n",
        "    if path.name.lower().endswith(nii_exts):\n",
        "        img = nib.load(str(path))\n",
        "        arr = img.get_fdata()\n",
        "        # if this is a 3D volume, you might want to decide how to handle it—\n",
        "        # here we assume 2D or single-slice\n",
        "        return np.asarray(arr, dtype=np.float32)\n",
        "    else:\n",
        "        return imread(str(path)).astype(np.float32)\n",
        "\n",
        "# load images\n",
        "test_data = [load_image(f) for f in img_files]\n",
        "\n",
        "# load ground‐truth if available\n",
        "if gt_dir.exists():\n",
        "    mask_files = sorted([\n",
        "        f for f in gt_dir.iterdir()\n",
        "        if f.suffix.lower() in img_exts\n",
        "           or f.name.lower().endswith(nii_exts)\n",
        "    ])\n",
        "    test_labels = [load_image(f) for f in mask_files]\n",
        "else:\n",
        "    test_labels = None\n",
        "\n",
        "# initialize your trained Cellpose model\n",
        "model = models.CellposeModel(gpu=True, \n",
        "                            pretrained_model=trained_model)\n",
        "\n",
        "# run inference\n",
        "masks, flows, styles = model.eval(test_data, batch_size=32)\n",
        "\n",
        "### # evaluate if ground‐truth was provided\n",
        "### if test_labels is not None:\n",
        "###     ap = metrics.average_precision(test_labels, masks)[0]\n",
        "###     mean_ap50 = ap[:,0].mean()\n",
        "###     print(f\">>> average precision at IoU=0.5 : {mean_ap50:.3f}\\n\")\n",
        "\n",
        "# save out each predicted mask\n",
        "for img_path, mask in zip(img_files, masks):\n",
        "    out_path = out_dir / f\"{img_path.stem}_mask.tif\"\n",
        "    # cast to uint16 (or uint8) as needed\n",
        "    imwrite(str(out_path), mask.astype(np.uint16))\n",
        "\n",
        "print(f\"Saved {len(masks)} predicted masks to:\\n  {out_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from tifffile import imread, imwrite\n",
        "import nibabel as nib\n",
        "from cellpose import models, metrics\n",
        "\n",
        "\n",
        "# path to the folder containing test images\n",
        "test_dir = Path(\"/scratch/msa6093/OverlappingPatches-Y/s4\")\n",
        "\n",
        "# (optional) path to the folder containing ground‐truth masks\n",
        "gt_dir   = Path(\"/path/to/your/gt_masks\")\n",
        "\n",
        "# where to save the predicted masks\n",
        "out_dir  = test_dir / \"/scratch/msa6093/Full_Masks_Overlapping_Y/s4\"\n",
        "\n",
        "# trained Cellpose model file\n",
        "trained_model = \"/scratch/msa6093/Daphnia392/models/CuratedTrainingData_May28_2Axes\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# make sure output directory exists\n",
        "out_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# gather all image files in test_dir\n",
        "img_exts = {\".tif\", \".tiff\", \".png\", \".jpg\", \".jpeg\"}\n",
        "nii_exts = (\".nii\", \".nii.gz\")\n",
        "\n",
        "# gather all image files in test_dir\n",
        "img_files = sorted([\n",
        "    f for f in test_dir.iterdir()\n",
        "    if f.suffix.lower() in img_exts\n",
        "       or f.name.lower().endswith(nii_exts)\n",
        "])\n",
        "\n",
        "# load images\n",
        "def load_image(path: Path):\n",
        "    if path.name.lower().endswith(nii_exts):\n",
        "        img = nib.load(str(path))\n",
        "        arr = img.get_fdata()\n",
        "        # if this is a 3D volume, you might want to decide how to handle it—\n",
        "        # here we assume 2D or single-slice\n",
        "        return np.asarray(arr, dtype=np.float32)\n",
        "    else:\n",
        "        return imread(str(path)).astype(np.float32)\n",
        "\n",
        "# load images\n",
        "test_data = [load_image(f) for f in img_files]\n",
        "\n",
        "# load ground‐truth if available\n",
        "if gt_dir.exists():\n",
        "    mask_files = sorted([\n",
        "        f for f in gt_dir.iterdir()\n",
        "        if f.suffix.lower() in img_exts\n",
        "           or f.name.lower().endswith(nii_exts)\n",
        "    ])\n",
        "    test_labels = [load_image(f) for f in mask_files]\n",
        "else:\n",
        "    test_labels = None\n",
        "\n",
        "# initialize your trained Cellpose model\n",
        "model = models.CellposeModel(gpu=True, \n",
        "                            pretrained_model=trained_model)\n",
        "\n",
        "# run inference\n",
        "masks, flows, styles = model.eval(test_data, batch_size=32)\n",
        "\n",
        "### # evaluate if ground‐truth was provided\n",
        "### if test_labels is not None:\n",
        "###     ap = metrics.average_precision(test_labels, masks)[0]\n",
        "###     mean_ap50 = ap[:,0].mean()\n",
        "###     print(f\">>> average precision at IoU=0.5 : {mean_ap50:.3f}\\n\")\n",
        "\n",
        "# save out each predicted mask\n",
        "for img_path, mask in zip(img_files, masks):\n",
        "    out_path = out_dir / f\"{img_path.stem}_mask.tif\"\n",
        "    # cast to uint16 (or uint8) as needed\n",
        "    imwrite(str(out_path), mask.astype(np.uint16))\n",
        "\n",
        "print(f\"Saved {len(masks)} predicted masks to:\\n  {out_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from tifffile import imread, imwrite\n",
        "import nibabel as nib\n",
        "from cellpose import models, metrics\n",
        "\n",
        "\n",
        "# path to the folder containing test images\n",
        "test_dir = Path(\"/scratch/msa6093/OverlappingPatches-Y/s5\")\n",
        "\n",
        "# (optional) path to the folder containing ground‐truth masks\n",
        "gt_dir   = Path(\"/path/to/your/gt_masks\")\n",
        "\n",
        "# where to save the predicted masks\n",
        "out_dir  = test_dir / \"/scratch/msa6093/Full_Masks_Overlapping_Y/s5\"\n",
        "\n",
        "# trained Cellpose model file\n",
        "trained_model = \"/scratch/msa6093/Daphnia392/models/CuratedTrainingData_May28_2Axes\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# make sure output directory exists\n",
        "out_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# gather all image files in test_dir\n",
        "img_exts = {\".tif\", \".tiff\", \".png\", \".jpg\", \".jpeg\"}\n",
        "nii_exts = (\".nii\", \".nii.gz\")\n",
        "\n",
        "# gather all image files in test_dir\n",
        "img_files = sorted([\n",
        "    f for f in test_dir.iterdir()\n",
        "    if f.suffix.lower() in img_exts\n",
        "       or f.name.lower().endswith(nii_exts)\n",
        "])\n",
        "\n",
        "# load images\n",
        "def load_image(path: Path):\n",
        "    if path.name.lower().endswith(nii_exts):\n",
        "        img = nib.load(str(path))\n",
        "        arr = img.get_fdata()\n",
        "        # if this is a 3D volume, you might want to decide how to handle it—\n",
        "        # here we assume 2D or single-slice\n",
        "        return np.asarray(arr, dtype=np.float32)\n",
        "    else:\n",
        "        return imread(str(path)).astype(np.float32)\n",
        "\n",
        "# load images\n",
        "test_data = [load_image(f) for f in img_files]\n",
        "\n",
        "# load ground‐truth if available\n",
        "if gt_dir.exists():\n",
        "    mask_files = sorted([\n",
        "        f for f in gt_dir.iterdir()\n",
        "        if f.suffix.lower() in img_exts\n",
        "           or f.name.lower().endswith(nii_exts)\n",
        "    ])\n",
        "    test_labels = [load_image(f) for f in mask_files]\n",
        "else:\n",
        "    test_labels = None\n",
        "\n",
        "# initialize your trained Cellpose model\n",
        "model = models.CellposeModel(gpu=True, \n",
        "                            pretrained_model=trained_model)\n",
        "\n",
        "# run inference\n",
        "masks, flows, styles = model.eval(test_data, batch_size=32)\n",
        "\n",
        "### # evaluate if ground‐truth was provided\n",
        "### if test_labels is not None:\n",
        "###     ap = metrics.average_precision(test_labels, masks)[0]\n",
        "###     mean_ap50 = ap[:,0].mean()\n",
        "###     print(f\">>> average precision at IoU=0.5 : {mean_ap50:.3f}\\n\")\n",
        "\n",
        "# save out each predicted mask\n",
        "for img_path, mask in zip(img_files, masks):\n",
        "    out_path = out_dir / f\"{img_path.stem}_mask.tif\"\n",
        "    # cast to uint16 (or uint8) as needed\n",
        "    imwrite(str(out_path), mask.astype(np.uint16))\n",
        "\n",
        "print(f\"Saved {len(masks)} predicted masks to:\\n  {out_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MUrvy5JqmE-"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,8), dpi=150)\n",
        "for k,im in enumerate(test_data):\n",
        "    img = im.copy()\n",
        "    plt.subplot(3,len(test_data), k+1)\n",
        "    img = np.vstack((img, np.zeros_like(img)[:1]))\n",
        "    img = img.transpose(1,2,0)\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    if k==0:\n",
        "        plt.title('image')\n",
        "\n",
        "    plt.subplot(3,len(test_data), len(test_data) + k+1)\n",
        "    plt.imshow(masks[k])\n",
        "    plt.axis('off')\n",
        "    if k==0:\n",
        "        plt.title('predicted labels')\n",
        "\n",
        "    plt.subplot(3,len(test_data), 2*len(test_data) + k+1)\n",
        "    plt.imshow(test_labels[k])\n",
        "    plt.axis('off')\n",
        "    if k==0:\n",
        "        plt.title('true labels')\n",
        "plt.tight_layout()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (cellpose-env)",
      "language": "python",
      "name": "cellpose-env"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
